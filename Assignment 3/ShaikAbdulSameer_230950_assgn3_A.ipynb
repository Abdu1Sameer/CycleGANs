{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wg6hsKMq398n"
      },
      "source": [
        "# ASSIGNMENT 3\n",
        "PART A consists of theoretical questions. Objective answers will receive zero marks. You need to write detailed answers (200-300 words) for the questions that require more in-depth explanations (you should be able to identify these after reading and finding about them). Questions that need less explanation can be answered in 95-150 words. Please ensure the answers are well-written and thorough."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFQN0GPrnSd3"
      },
      "source": [
        "# PART A"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuKQGaqx2a5i"
      },
      "source": [
        "Q 1)What are optimizers in ML. Give some examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g24HErpiknPY"
      },
      "source": [
        "Optimizers are algorithms used to find the optimal set of parameters for a model during the training process. These algorithms adjust the weights and biases in the model iteratively until they converge on a minimum loss value. Optimizer reduce the training time also .\n",
        "\n",
        "Examples-\n",
        "\n",
        "1)Momentum :\n",
        "Momentum optimizer updates weights by v(i) = a*v(i-1)+(1-a)*(dw) and w = w - (k)*(v(i))\n",
        "and v(i) = a*v(i-1)+(1-a)*(db)  b=b-(k)*(v(i)) , it reduces the zigzag movement especially in mini batch gradient descent and reduces the training time\n",
        "\n",
        "2)RMSprop:\n",
        "Similar to the above but updates the weights and bias by the formula\n",
        "s(dw)(i)=(a)*(s(dw)(i-1)) + (1-a)*(dw)*(dw)\n",
        "s(db)(i)=(a)*(s(db)(i-1)) + (1-a)*(db)*(db)\n",
        "w=w-((k)*(dw))/sqrt(s(dw)(i) + e)\n",
        "b=b-((k)*(db))/sqrt(s(db)(i) + e)\n",
        "\n",
        "3)Adam:\n",
        "It is combination of both of the above optimizers\n",
        "Taking v(i) from momentum and s(i) from rmsprop\n",
        "adam uses w= w -((k)*(v(i))/sqrt(s(dw)(i) + e)\n",
        "b= b -((k)*(v(i))/sqrt(s(db)(i) + e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8GPK5j_2n3P"
      },
      "source": [
        "Q 2)Explain the difference between Gradient Descent, Stochastic Gradient Descent, Mini-Batch Gradient Descent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In gradient descent we write the loss function by using the mean square of all points in the data ,In stochastic gradient descent we write the loss function by using the mean square for only one point at a time in data thus reducing the time complexity which is helpful if there are multiple features in the data and in mini-batch gradient descent we write the loss function by using the mean square for only a set of points at a time .In SGD,Due to its stochastic nature, the path towards the global cost minimum is not “direct” as in Gradient Descent, but may go “zig-zag” if we are visuallizing the cost surface in a 2D space, optimizers will be helpful in making this path direct.Stochastic Gradient Descent: Faster convergence rate due to the use of single training examples in each iteration. Gradient Descent: Slower convergence rate, as it uses the entire dataset for each iteration.\n",
        "SGD adds even more noise to the learning process than mini-batch that helps improving generalization error. However, this would increase the run time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AG5Rm7c2sAO"
      },
      "source": [
        "Q 3)Explain about Adam optimizer in detail"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "The Adam optimizer, short for “Adaptive Moment Estimation,” is an iterative optimization algorithm used to minimize the loss function during the training of neural networks. Adam can be looked at as a combination of RMSprop and Stochastic Gradient Descent with momentum.\n",
        "\n",
        "It is combination of rmsprop and momentum Taking v(i) from momentum and s(i) from rmsprop\n",
        "adam updates weights by\n",
        "\n",
        "w= w -((k)*(v(i))/sqrt(s(dw)(i) + e) and b= b -((k)*(v(i))/sqrt(s(db)(i) + e)\n",
        "Adam optimizer gives much higher performance than other optimizers and outperforms them by a big margin into giving an optimized gradient descent.\n",
        "\n",
        "Adaptive Learning Rates:\n",
        "\n",
        "Adam adapts the learning rates for each parameter based on the magnitudes of their gradients, allowing for faster learning without the need for manual tuning.\n",
        "\n",
        "\n",
        "Sparse Gradient Handling:\n",
        "\n",
        "Adam handles sparse gradients well by dynamically adjusting the learning rates based on the magnitude of the gradients.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0I65BBb2w84"
      },
      "source": [
        "Q 4)Explain the difference between Rmsprop and Adam."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "RMSprop (Root Mean Square Propagation)\n",
        "Algorithm Characteristics:\n",
        "Adaptive Learning Rate: RMSprop adjusts the learning rate for each parameter individually by dividing the learning rate by an exponentially decaying average of squared gradients.\n",
        "Decay Parameter: The decay parameter (beta) is typically set around 0.9. It controls the rate at which the running average is updated.\n",
        "Advantages:\n",
        "Adaptive Learning Rates: Helps in handling the problem of vanishing and exploding gradients by adapting learning rates.\n",
        "Simplicity: Straightforward implementation and computational efficiency.\n",
        "Disadvantages:\n",
        "Hyperparameter Sensitivity: Performance can be sensitive to the choice of decay parameter and learning rate.\n",
        "Adam (Adaptive Moment Estimation)\n",
        "Algorithm Characteristics:\n",
        "Adam combines the ideas of both momentum and RMSprop. It maintains two moving averages: one for the gradients (first moment) and one for the squared gradients (second moment).\n",
        "Bias Correction: Adam includes bias correction terms to counteract the initialization bias in the moving averages.\n",
        "Advantages:\n",
        "Adaptive Learning Rates: Like RMSprop, Adam adjusts learning rates individually for each parameter.\n",
        "Momentum Term: The inclusion of momentum helps in smoothing the optimization path.\n",
        "Bias Correction: Helps in stabilizing the algorithm, especially in early iterations.\n",
        "this also work well in practice and is less sensitive to hyperparameter settings compared to RMSprop.\n",
        "Disadvantages:\n",
        "Complexity: Slightly more complex than RMSprop due to the additional calculations and hyperparameters.\n",
        "Computational Overhead: Marginally higher computational cost due to maintaining two moving averages and bias correction terms.\n",
        "Both RMSprop and Adam  adapt learning rates based on the gradients, making them well-suited for training deep networks where gradient magnitudes can vary significantly.\n",
        "RMSprop: Simpler, focuses solely on normalizing gradients using a moving average of squared gradients.\n",
        "Adam: Combines the benefits of momentum and RMSprop, includes bias correction, and generally performs better in practice.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVYyIYOe2w_k"
      },
      "source": [
        "Q 5)What do you think is the best optimizer among all and Why? If you cannot come to conclusive answer, you must list them all and tell in which scenario the one is preferred.Also tell the disadvantages."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "RMSprop (Root Mean Square Propagation)\n",
        "\n",
        "When to Use:\n",
        "Non-stationary settings where learning rates need to adapt quickly.\n",
        "Deep learning tasks with varying gradients.\n",
        "Training neural networks where the learning rate needs to be adjusted individually for each parameter.\n",
        "\n",
        "Disadvantages:\n",
        "Requires tuning of decay parameters (typically around 0.9).\n",
        "Can be sensitive to hyperparameter settings.\n",
        "May not perform as well on problems where momentum is beneficial.\n",
        "\n",
        "Momentum\n",
        "\n",
        "When to Use:\n",
        "Scenarios where Stochastic Gradient Descent (SGD) is used, but convergence needs to be faster.\n",
        "Problems with noisy gradients.\n",
        "Tasks where accelerating the optimization process is crucial.\n",
        "\n",
        "Disadvantages:\n",
        "Requires careful tuning of both the learning rate and the momentum term (typically around 0.9).\n",
        "Still sensitive to the initial learning rate.\n",
        "Does not adapt learning rates individually for each parameter.\n",
        "\n",
        "Adam (Adaptive Moment Estimation)\n",
        "\n",
        "When to Use:\n",
        "\n",
        "General-purpose deep learning tasks.\n",
        "Situations where robust and efficient convergence is desired.\n",
        "Particularly effective in tasks with sparse gradients or noisy gradients.\n",
        "Tasks that require adaptive learning rates for each parameter.\n",
        "\n",
        "Disadvantages:\n",
        "\n",
        "Slightly more complex due to additional parameters (momentum terms and bias correction).\n",
        "Can sometimes perform poorly on specific problems without hyperparameter tuning.\n",
        "Requires careful tuning of hyperparameters (default settings:\n",
        "B1=0.9 B2=0.999, learning rate)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKxnf5et2xDF"
      },
      "source": [
        "Q 6)What is overfitting and underfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Overfitting:\n",
        "\n",
        "Overfitting occurs when a model learns not only the underlying pattern in the training data but also the noise and outliers. As a result, the model performs exceptionally well on the training data but poorly on unseen test data.\n",
        "This may happen because of Too Complex Model: Using a model with too many parameters or high complexity (e.g., deep neural networks with many layers).\n",
        "Insufficient Training Data: Not enough data to cover the underlying pattern comprehensively.\n",
        "Lack of Regularization: No regularization techniques to penalize model complexity.\n",
        "\n",
        "Underfitting:\n",
        "\n",
        "Underfitting occurs when a model is too simple to capture the underlying pattern in the data. The model performs poorly on both the training data and unseen test data.Reasons can be Using a model that is too basic or has insufficient parameters (e.g., a linear model for non-linear data)or The model hasn't been trained long enough ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UCncA8M2xF5"
      },
      "source": [
        "Q 7)Explain the vanishing and exploding gradients"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1)Vanishing Gradients:\n",
        "\n",
        "Vanishing gradients occur when the gradients of the loss function with respect to the model parameters become very small during backpropagation. As a result, the updates to the weights are tiny, and the model learns very slowly or not at all.\n",
        "Reasons can be\n",
        "Activation Functions, Certain activation functions, such as the sigmoid and tanh, squash their input into a small range (e.g., between 0 and 1 for sigmoid), leading to gradients that diminish rapidly as they propagate back through the network.\n",
        "Deep Networks,The deeper the network, the more likely it is that the gradients will diminish to very small values as they are multiplied through each layer.\n",
        "\n",
        "2)Exploding gradients:\n",
        "\n",
        "Exploding gradients occur when the gradients of the loss function with respect to the model parameters become very large during backpropagation. This causes the updates to the weights to be excessively large, leading to unstable models and diverging loss values.\n",
        "Reasons can be\n",
        "Deep Networks: Similar to vanishing gradients, deep networks are more susceptible to exploding gradients as the product of gradients through many layers can grow exponentially.\n",
        "Poor Weight Initialization: Improper initialization of weights can contribute to the problem by leading to large gradient values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNW8Hmd52xIn"
      },
      "source": [
        "Q 8)Explain batch and layer normalization in detail."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Batch Normalization (BN):\n",
        "\n",
        "Batch normalization normalizes the input of each layer in a neural network to have a mean of zero and a variance of one for each mini-batch during training. This normalization helps to stabilize and accelerate the training process.Calculate Mean and Variance:\n",
        "For a given mini-batch, compute the mean and variance of the input activations.\n",
        "Normalize the input activations using the computed mean and variance.\n",
        "Apply a linear transformation to the normalized activations to allow the network to learn the optimal scale and shift.\n",
        "\n",
        "Advantages:\n",
        "\n",
        "Improved Training Speed: Allows for higher learning rates, reducing the training time.\n",
        "Reduced Sensitivity to Initialization: Less dependent on careful weight initialization.\n",
        "Regularization Effect: Acts as a form of regularization, potentially reducing the need for other regularization techniques \n",
        "\n",
        "Layer Normalization (LN):\n",
        "\n",
        "Layer normalization normalizes the input across the features for each individual training example, rather than across the mini-batch. This method is particularly useful for recurrent neural networks (RNNs) and works well when batch sizes are small.Calculate Mean and Variance:\n",
        "For each training example, compute the mean\n",
        "μ and variance of the input activations across the features.\n",
        "Normalize the input activations using the computed mean and variance.\n",
        "Apply a linear transformation to the normalized activations.\n",
        "\n",
        "Advantages:\n",
        "\n",
        "Independence from Mini-Batch Size: Does not depend on the mini-batch size, making it suitable for smaller batch sizes or RNNs.\n",
        "Stabilizes Training: Helps in stabilizing the training of deep networks, especially RNNs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pMnZ6z52xLa"
      },
      "source": [
        "Q 9)What are regularization techniques in machine learning?(200 words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Regularization is a technique used to prevent overfitting by adding a penalty term to the loss function, discouraging the model from assigning too much importance to individual features or coefficients.Regularization helps control model complexity by preventing overfitting to training data, resulting in better generalization to new data.Regularization can help balance between model bias (underfitting) and model variance (overfitting) in machine learning, which leads to improved performance.Regularization is a technique used to reduce errors by fitting the function appropriately on the given training set and avoiding overfitting. The commonly used regularization techniques are :\n",
        "\n",
        "Lasso Regularization – L1 Regularization\n",
        "\n",
        "Adds a penalty equal to the absolute value of the magnitude of coefficients.\n",
        "Encourages sparsity, leading to models with fewer parameters.May not always converge to a single solution if features are highly correlated.\n",
        "\n",
        "Ridge Regularization – L2 Regularization\n",
        "\n",
        "Adds a penalty equal to the square of the magnitude of coefficients.\n",
        "Tends to shrink coefficients evenly but does not set them to zero.Does not perform feature selection, so all features remain in the model.\n",
        "\n",
        "Elastic Net Regularization – L1 and L2 Regularization\n",
        "\n",
        "Combines L1 and L2 regularization.\n",
        "Useful when there are multiple correlated features.Can perform feature selection while maintaining some regularization of coefficients.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoVZoLpB3B7X"
      },
      "source": [
        "Q 10)What is dropout layer and explain how it prevents overfitting?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Dropout is a regularization technique used in neural networks to prevent overfitting by randomly deactivating (or \"dropping out\") a fraction of neurons during training.Dropout is implemented as a layer in neural networks, typically applied after the activation function of each hidden layer.\n",
        "During training, each neuron in the dropout layer has a probability p of being retained (not dropped out) and a probability of 1−p of being dropped out.\n",
        "At test time, all neurons are used, but their outputs are scaled by the retention probability p to account for the dropout during training.\n",
        "\n",
        "How it Prevents Overfitting:\n",
        "\n",
        "Reduces Co-Adaptation:\n",
        "Dropout prevents neurons from co-adapting too much by randomly dropping them out during training. This encourages neurons to learn more robust features independently.\n",
        "\n",
        "Ensemble Learning Effect:\n",
        "Dropout can be seen as training multiple neural networks with shared weights. Each dropout mask during training corresponds to a different subnetwork, and the final model approximates the average of all these subnetworks.\n",
        "\n",
        "Implicit Model Averaging:\n",
        "Dropout acts as a form of model averaging, as each iteration trains a different subnetwork. This helps in reducing overfitting by providing a regularizing effect.\n",
        "\n",
        "Effective Regularization:\n",
        "By effectively preventing the model from relying too heavily on any particular set of features or neurons, dropout acts as a regularization technique, helping to prevent overfitting to the training data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMx3OcJ53CBj"
      },
      "source": [
        "Q 11)Explain L1 and L2 regularization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "L1 Regularization (Lasso)\n",
        "\n",
        "Concept:\n",
        "L1 regularization adds a penalty equal to the absolute value of the magnitude of the coefficients. This penalty term encourages sparsity, meaning it drives some of the coefficients to zero, effectively performing feature selection.\n",
        "\n",
        "Advantages:\n",
        "\n",
        "Sparsity: L1 regularization tends to produce sparse models with few non-zero coefficients, which can be useful for feature selection.\n",
        "Interpretable Models: The resulting models are often simpler and easier to interpret.\n",
        "\n",
        "Disadvantages:\n",
        "\n",
        "Non-Smooth Optimization: The absolute value function is not differentiable at zero, which can make optimization more challenging.\n",
        "\n",
        "L2 Regularization (Ridge)\n",
        "Concept:\n",
        "L2 regularization adds a penalty equal to the square of the magnitude of the coefficients. This penalty term discourages large weights uniformly, shrinking all coefficients but not setting them to zero.\n",
        "\n",
        "Advantages:\n",
        "\n",
        "Smooth Optimization: The squared penalty is differentiable everywhere, making the optimization problem easier to solve.\n",
        "Numerical Stability: Helps in making the model more numerically stable and robust to collinearity (correlation among features).\n",
        "\n",
        "Disadvantages:\n",
        "\n",
        "No Feature Selection: L2 regularization does not produce sparse models, as it shrinks coefficients but does not eliminate them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5TGmHuJ3JTh"
      },
      "source": [
        "Q 12)Write about validation accuracy and why we need it?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Validation accuracy is a metric used to evaluate a machine learning model's performance on a validation dataset, which is a subset of the data that is not used during the training process. It represents the proportion of correctly predicted instances out of the total instances in the validation set. This metric helps in assessing how well the model generalizes to unseen data.\n",
        "\n",
        "Validation accuracy is a crucial metric for assessing the performance and generalization ability of a machine learning model. It ensures that the model does not overfit to the training data, aids in hyperparameter tuning, supports early stopping, guides model selection, and helps monitor training performance. By focusing on validation accuracy, practitioners can build models that perform well on real-world, unseen data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCOGr8vl3JXY"
      },
      "source": [
        " Q 13)What do you mean by data augmentation and explain is advantages and disadvantages in detail?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Data augmentation refers to the process of artificially increasing the size of a dataset by applying various transformations to the existing data samples. These transformations include rotations, translations, scaling, flipping, cropping, and adding noise, among others.\n",
        "\n",
        "Advantages:\n",
        "\n",
        "Increased Dataset Size: Data augmentation expands the training dataset, providing more diverse examples for the model to learn from, which can improve generalization.\n",
        "\n",
        "By exposing the model to a wider range of variations in the data, data augmentation helps in making the model more robust to different input conditions and variations.\n",
        "\n",
        "Reduced Overfitting: With a larger and more varied dataset, the risk of overfitting is reduced, as the model is less likely to memorize specific examples and instead learns more generalizable patterns.\n",
        "\n",
        "Enhanced Performance: Augmenting the data can lead to better model performance, especially in scenarios where the original dataset is small or limited in diversity.\n",
        "\n",
        "Data augmentation techniques can help in adapting the model to different domains or environments by simulating variations that may occur in real-world scenarios.\n",
        "\n",
        "Disadvantages:\n",
        "\n",
        "Computational Overhead: Generating augmented data requires additional computational resources, particularly for large datasets and complex transformations, which can increase training time.\n",
        "\n",
        "Loss of Information: Some transformations may introduce noise or distortions that alter the original information in the data, potentially affecting model performance negatively.\n",
        "\n",
        "Certain augmentation techniques may not be applicable or effective for all types of data or domains. Choosing appropriate transformations requires domain knowledge and experimentation.\n",
        "\n",
        "Increased Complexity: Managing augmented datasets and ensuring consistency across transformations can add complexity to the training pipeline and data preprocessing.\n",
        "\n",
        "The effectiveness of data augmentation techniques may depend on the choice of hyperparameters such as the type and magnitude of transformations applied, which may require tuning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CeYHJXKh3O1x"
      },
      "source": [
        "Q 14)What is transfer learning.Explain in detail? Mention various pre-trained model present in the community"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Transfer learning is a machine learning technique where a model trained on one task is repurposed or adapted to perform a related but different task. Instead of training a model from scratch, transfer learning leverages knowledge learned from a source domain and applies it to a target domain. This approach is particularly useful when the target dataset is small or lacks sufficient labeled examples for training a model from scratch.\n",
        "\n",
        "How Transfer Learning Works:\n",
        "\n",
        "Pre-trained Model: A pre-trained model is trained on a large dataset for a specific task, such as image classification or natural language processing (NLP). The pre-trained model learns generic features and patterns from the data.\n",
        "\n",
        "Feature Extraction: In transfer learning, the pre-trained model's learned features are used as a starting point for the target task. The pre-trained model is typically truncated at a certain layer, and the learned features (activations) from this layer are extracted as fixed representations of the input data.\n",
        "\n",
        "Optionally, the extracted features can be further fine-tuned or adapted to the target task by training additional layers or the entire model on the target dataset. Fine-tuning helps the model learn task-specific patterns and optimize performance on the target task.\n",
        "\n",
        "There are several pre-trained models available in the community across different domains, trained on large datasets. Some popular pre-trained models include:\n",
        "\n",
        "Image Classification:\n",
        "\n",
        "VGG (Visual Geometry Group): VGG models consist of multiple layers with small filters, trained on the ImageNet dataset for image classification.\n",
        "ResNet (Residual Network): ResNet models introduce residual connections to address the vanishing gradient problem, achieving deeper architectures while maintaining performance.\n",
        "\n",
        "Natural Language Processing (NLP):\n",
        "Word2Vec and GloVe: Word embedding models like Word2Vec and GloVe learn vector representations of words from large text corpora, capturing semantic relationships between words.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0x7E-Cg3Vzc"
      },
      "source": [
        "Q 15) Explain the bias- variance tradeoff."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The bias-variance tradeoff is a fundamental concept in machine learning that describes the relationship between the bias of a model, its variance, and its overall performance. Understanding this tradeoff is crucial for building models that generalize well to unseen data.\n",
        "\n",
        "Bias measures how closely the predictions of a model match the true values in the training data.\n",
        "A high bias indicates that the model is too simple.\n",
        " \n",
        "Variance measures the variability of model predictions for different training datasets. A high variance indicates that the model is too complex and captures noise in the training data.\n",
        "\n",
        "Tradeoff:\n",
        "The bias-variance tradeoff describes the balance between bias and variance in machine learning models.\n",
        "\n",
        "High Bias Models:\n",
        "\n",
        "Simple models with high bias and low variance.\n",
        "Tradeoff Implication: While these models may be less prone to overfitting, they are limited in their ability to capture complex patterns in the data.\n",
        "High Variance Models:\n",
        "\n",
        "Complex models with low bias and high variance.\n",
        "Tradeoff Implication: These models may capture complex patterns well in the training data, but they are more likely to overfit and generalize poorly to unseen data.\n",
        "\n",
        "The goal in machine learning is to find the optimal balance between bias and variance that minimizes the model's total error on unseen data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUU9eDCa3S2U"
      },
      "source": [
        "Q 16)Assume you have dataset of patients who visited AIIMS(Delhi) between the period of 2018-2020.The datasets include features from CBC reports,IGE,weight,temp,etc.There problems were mainly classified into gastrointestinal problems, heart problems, diabetes and misc.\n",
        "You being a experienced ML engineer, the hospital has approached you to make a model which given these features can predict the problem that the patient is suffering.You can either train a separate neural network for each of the diseases or to train a single neural network\n",
        "with one output neuron for each disease. Which method do you prefer.Justify your answer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this case where the goal is to predict the medical problem based on patient features, I would prefer to train a single neural network with one output neuron for each disease\n",
        "\n",
        "Single Neural Network with Multiple Outputs:\n",
        "\n",
        "Advantages:\n",
        "\n",
        "Simplicity:\n",
        "\n",
        "Training a single neural network simplifies the model architecture and management compared to training separate networks for each disease. It reduces redundancy in model development and maintenance.\n",
        "Having one model with multiple outputs allows for easier interpretation and analysis of the relationships between patient features and various diseases. It provides a unified framework for understanding disease prediction.\n",
        "\n",
        "Data Efficiency:\n",
        "\n",
        "Training a single model with multiple outputs allows for better utilization of the available data, especially in scenarios where certain diseases have limited samples. The shared representations help in transferring knowledge between diseases.A single model can be easily scaled to accommodate additional diseases or conditions in the future without significant modifications to the architecture.\n",
        "\n",
        "Regularization:\n",
        "\n",
        "Training a single model with multiple outputs can potentially provide regularization benefits by jointly learning multiple tasks, reducing the risk of overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRbqSHnH0Cu5"
      },
      "source": [
        "Q 17) Assume your input data X has m observations and n0 features (shape: n0 x m), and the output layer Y has shape (n3 x m). Say that you want to have 2 hidden layers in your model: A1- (n1 x m) and A2- (n2 x m).\n",
        "\n",
        "(a) How many weight and bias matrices will you have? Find the shapes of each & verify if the dimensions of matrix multiplications are accurate.\n",
        "\n",
        "(b) If this is a Binary classification problem, what activation functions will you use for (i) the hidden layers, and (ii) the output layer. Why?\n",
        "\n",
        "(c) Repeat part (b) if this is a Multi-class classification problem.\n",
        "\n",
        "(d) Repeat part (b) if this is a Regression problem.\n",
        "\n",
        "-> Give proper reasoning for each part."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's break down each part of the question:\n",
        "\n",
        "(a) Weight and Bias Matrices:\n",
        "\n",
        "Weight Matrices:\n",
        "\n",
        "Between Input Layer and Hidden Layer 1 (A1): \n",
        "W[1] with shape (n1 x n0)\n",
        "Between Hidden Layer 1 (A1) and Hidden Layer 2 (A2): \n",
        "W[2] with shape (n2 x n1)\n",
        "Between Hidden Layer 2 (A2) and Output Layer: \n",
        "W[3] with shape (n3 x n2)\n",
        "\n",
        "Bias Vectors:\n",
        "\n",
        "Bias for Hidden Layer 1 (A1): \n",
        "b[1] with shape (n1 x 1)\n",
        "Bias for Hidden Layer 2 (A2): \n",
        "b[2] with shape (n2 x 1)\n",
        "Bias for Output Layer:  \n",
        "b[3] with shape (n3 x 1)\n",
        "\n",
        "so we have 3 weight and 3 bias matrices\n",
        "\n",
        "(b) Activation Functions for Binary Classification:\n",
        "For a binary classification problem:\n",
        "\n",
        "Hidden Layers:\n",
        "I will use ReLU (Rectified Linear Unit) or Sigmoid activation functions.\n",
        "f(x)=max(0,x) is often preferred due to its simplicity and ability to handle the vanishing gradient problem.\n",
        "\n",
        "Output Layer:\n",
        "I will use Sigmoid activation function .\n",
        "\n",
        "Sigmoid squashes the output values between 0 and 1, representing the probability of the positive class.\n",
        "\n",
        "\n",
        "(c) Activation Functions for Multi-class Classification:\n",
        "For a multi-class classification problem:\n",
        "\n",
        "Hidden Layers:\n",
        "I will use ReLU activation function for the hidden layers due to its simplicity and ability to handle the vanishing gradient problem.\n",
        "\n",
        "Output Layer:\n",
        "I will use Softmax activation function .\n",
        "\n",
        "Softmax normalizes the output vector into a probability distribution over multiple classes, ensuring that the sum of probabilities equals 1.\n",
        "\n",
        "(d) Activation Functions for Regression:\n",
        "\n",
        "For a regression problem:\n",
        "\n",
        "Hidden Layers:\n",
        "I will use ReLU activation function for the hidden layers due to its simplicity and ability to handle the vanishing gradient problem.\n",
        "\n",
        "Output Layer:\n",
        "I will use Linear activation function .\n",
        "Linear activation allows the network to output continuous values without imposing any constraints or transformations."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
