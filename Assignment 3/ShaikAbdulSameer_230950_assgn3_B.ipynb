{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8VDe2CfGe1C"
      },
      "source": [
        "# Part B (Neural Network from Scratch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWcVTpevGpfs"
      },
      "source": [
        "You need to implement a neural network from scratch .This is a multiclass classification problem. No. of hidden layers depends on you but should be atleast 2.Remember to use activation function. You can add any other function of your choice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G79JnP4t4Eqw"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KmTgnciWFC0O"
      },
      "outputs": [],
      "source": [
        "from sklearn import datasets\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "X=X.T\n",
        "y = iris.target\n",
        "temp=y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVPMgOfMFC3o",
        "outputId": "9c695d71-0981-4491-b8e7-620b2b0cdc7f"
      },
      "outputs": [],
      "source": [
        "print(X.shape,y.shape)\n",
        "print(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def normalize_data(X):\n",
        "    mean = np.mean(X, axis=1)\n",
        "    std = np.std(X, axis=1)\n",
        "    \n",
        "    # Normalize the data\n",
        "    X_normalized=[]\n",
        "    for i in range(X.shape[0]):\n",
        "        X_normalized.append((X[i] - np.mean(X[i])) / np.std(X[i]))\n",
        "    \n",
        "    return np.array(X_normalized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X=normalize_data(X)\n",
        "# y=normalize_data(y)\n",
        "print(X,'\\n',y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def one_hot_enc(y):\n",
        "    n=len(np.unique(y))\n",
        "    mat=np.zeros((y.shape[0],n))\n",
        "    mat[np.arange(y.shape[0]),y]=1\n",
        "    return mat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y=one_hot_enc(y)\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usrSV41k8AUJ",
        "outputId": "959723de-37d5-442f-b480-343b32341712"
      },
      "outputs": [],
      "source": [
        "def parameters(layer_dimen):\n",
        "  # define the parameters of your nn initially using random lib.\n",
        "  param={}\n",
        "  l=len(layer_dimen)-1\n",
        "  for i in range(1,l+1):\n",
        "    param['w'+str(i)]=np.random.randn(layer_dimen[i],layer_dimen[i-1])\n",
        "    param['b'+str(i)]=np.zeros((layer_dimen[i],1))\n",
        "    # print(\"param w is \",'\\n',param['w'+str(i)],\"param b is \",param['b'+str(i)],end='\\n')\n",
        "  return param"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#activation functions\n",
        "def sigmoid(x):\n",
        "    return 1/(1+np.exp(-x))\n",
        "\n",
        "def relu(x):\n",
        "    return np.maximum(0,x)\n",
        "\n",
        "def softmax(x):\n",
        "    x_max = np.max(x)\n",
        "    exp_values = np.exp(x - x_max)\n",
        "    sum_exp_values = np.sum(exp_values)\n",
        "    softmax_values = exp_values / sum_exp_values\n",
        "    return softmax_values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def deriv_relu(x):\n",
        "    return np.where(x>0,1,0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08ynlWSI8M_L"
      },
      "outputs": [],
      "source": [
        "def forward(x,param,activation='relu'):\n",
        "    # function for forward propagation\n",
        "    L=len(param)//2\n",
        "    forward_cac={}\n",
        "    forward_cac['a0']=x\n",
        "    for i in range(1,L):\n",
        "        forward_cac['z'+str(i)]=param['w'+str(i)].dot(forward_cac['a'+str(i-1)])+param['b'+str(i)]\n",
        "        forward_cac['a'+str(i)]=relu(forward_cac['z'+str(i)])\n",
        "        # print(\"z is \",forward_cac['z'+str(i)],\"a is\",forward_cac['a'+str(i)],end=\"\\n\")\n",
        "    \n",
        "    forward_cac['z'+str(L)]=param['w'+str(L)].dot(forward_cac['a'+str(L-1)])+param['b'+str(L)]\n",
        "    forward_cac['a'+str(L)]=softmax(forward_cac['z'+str(L)])\n",
        "    \n",
        "    return forward_cac['a'+str(L)],forward_cac\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Fm79jv18Otc"
      },
      "outputs": [],
      "source": [
        "def cost_funct(aL,y):\n",
        "  # function for cost func if nece\n",
        "  m=y.shape[1]\n",
        "  cost=-(1/m)*(np.sum(y*np.log(aL)))\n",
        "  return cost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HctPDjITIeUq"
      },
      "outputs": [],
      "source": [
        "# use Gradient descent as of now as an optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OVGy14Vt_kN_"
      },
      "outputs": [],
      "source": [
        "def backward(al,param,forward_cac,y):\n",
        "  # function for backward propagation\n",
        "  grads={}\n",
        "  L=len(param)//2\n",
        "  m=y.shape[1]\n",
        "\n",
        "  grads[\"dz\"+str(L)]=al-y\n",
        "  grads[\"dw\"+str(L)]=(1/m)*np.dot(grads[\"dz\"+str(L)],forward_cac[\"a\"+str(L-1)].T)\n",
        "  grads[\"db\"+str(L)]=(1/m)*np.sum(grads[\"dz\"+str(L)],axis=1,keepdims=True)\n",
        "\n",
        "  for i in reversed(range(1,L)):\n",
        "    grads[\"dz\"+str(i)]=np.dot(param['w'+str(i+1)].T,grads[\"dz\"+str(i+1)])*(deriv_relu(forward_cac[\"a\"+str(i)]))\n",
        "    grads[\"dw\"+str(i)]=(1/m)*np.dot(grads[\"dz\"+str(i)],forward_cac[\"a\"+str(i-1)].T)\n",
        "    grads[\"db\"+str(i)]=(1/m)*np.sum(grads[\"dz\"+str(i)],axis=1,keepdims=True)\n",
        "    # print(\"grads of z is \",'\\n',grads[\"dz\"+str(i)],\"grads of w is \",'\\n',grads[\"dw\"+str(i)],\"grads of b is \",'\\n',grads[\"db\"+str(i)],end='\\n')\n",
        "  \n",
        "  return grads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YbBKpK55ITPg"
      },
      "outputs": [],
      "source": [
        "def update_parameters(param,grads,lr):\n",
        "#FUNCTION TO UPDATE PARAMETERS USING GD\n",
        "  L=len(param)//2\n",
        "  for i in range(1,L+1):\n",
        "    param[\"w\"+str(i)]=param[\"w\"+str(i)]-(lr*grads[\"dw\"+str(i)])\n",
        "    param[\"b\"+str(i)]=param[\"b\"+str(i)]-(lr*grads[\"db\"+str(i)])\n",
        "    # print(\"param w is \",'\\n',param['w'+str(i)],\"param b is \",param['b'+str(i)],end='\\n')\n",
        "  return param"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7DOBhxNIxST"
      },
      "outputs": [],
      "source": [
        "def model(x,y,layer_dim,lr,iter=100):\n",
        "  #function to train and build the whole model\n",
        "  param=parameters(layer_dim)\n",
        "  cf=[]\n",
        "  for i in range(0,iter):\n",
        "    al,forward_cac=forward(x,param)\n",
        "    grads=backward(al,param,forward_cac,y)\n",
        "    if i%10==0:\n",
        "      print(al,y)\n",
        "      # print(grads[\"dz\"+str(L)])\n",
        "    param=update_parameters(param,grads,lr)\n",
        "    cost=cost_funct(al,y)\n",
        "    cf.append(cost)\n",
        "  return param,cf\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pH7yhg6LI-R4"
      },
      "outputs": [],
      "source": [
        "#write down the predictions and the f1 score finally\n",
        "layer_dims=[X.shape[0],8,3]\n",
        "lr=0.0075\n",
        "iters=500\n",
        "y=y.T\n",
        "param,cf=model(X,y,layer_dims,lr,iters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def predict(X, param):\n",
        "    L=len(param)//2\n",
        "    for i in range(1,L):\n",
        "        forward_cac={}\n",
        "        forward_cac['a0']=X\n",
        "        for i in range(1,L):\n",
        "            forward_cac['z'+str(i)]=param['w'+str(i)].dot(forward_cac['a'+str(i-1)])+param['b'+str(i)]\n",
        "            forward_cac['a'+str(i)]=relu(forward_cac['z'+str(i)])\n",
        "            # print(\"z is \",forward_cac['z'+str(i)],\"a is\",forward_cac['a'+str(i)],end=\"\\n\")\n",
        "        \n",
        "        forward_cac['z'+str(L)]=param['w'+str(L)].dot(forward_cac['a'+str(L-1)])+param['b'+str(L)]\n",
        "        forward_cac['a'+str(L)]=softmax(forward_cac['z'+str(L)])\n",
        "        forward_cac['a'+str(L)]  = forward_cac['a'+str(L)].T\n",
        "        return np.argmax(forward_cac['a'+str(L)], axis=1)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = predict(X,param)\n",
        "print(\"y is\",temp,\"\\n\")\n",
        "print(\"y pred is \",y_pred,\"\\n\")\n",
        "print(y.shape)\n",
        "print(y_pred.shape)\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(temp, y_pred)\n",
        "print(f\"Test Accuracy: {accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "f1 = f1_score(temp, y_pred, average='weighted')\n",
        "print(f\"Weighted F1 Score: {f1}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
